{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b23de7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Imports & basic config\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.width\", 200)\n",
    "sns.set_theme(style=\"whitegrid\", context=\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21e1d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../../data/interim/merged_dataset.csv\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21e431f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnc\\AppData\\Local\\Temp\\ipykernel_9292\\3364282976.py:69: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return col.replace(mapping)\n",
      "C:\\Users\\johnc\\AppData\\Local\\Temp\\ipykernel_9292\\3364282976.py:69: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return col.replace(mapping)\n",
      "C:\\Users\\johnc\\AppData\\Local\\Temp\\ipykernel_9292\\3364282976.py:69: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return col.replace(mapping)\n",
      "C:\\Users\\johnc\\AppData\\Local\\Temp\\ipykernel_9292\\3364282976.py:69: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return col.replace(mapping)\n",
      "C:\\Users\\johnc\\AppData\\Local\\Temp\\ipykernel_9292\\3364282976.py:69: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return col.replace(mapping)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EDUC_LEVEL</th>\n",
       "      <th>HOUSEHOLD_HEAD_SEX</th>\n",
       "      <th>CURRENT_USE_TYPE</th>\n",
       "      <th>PATTERN_USE</th>\n",
       "      <th>CONTRACEPTIVE_USE_AND_INTENTION</th>\n",
       "      <th>WANT_LAST_CHILD</th>\n",
       "      <th>WANT_LAST_PREGNANCY</th>\n",
       "      <th>TOLD_ABT_SIDE_EFFECTS</th>\n",
       "      <th>SMOKE_CIGAR</th>\n",
       "      <th>RESIDING_WITH_PARTNER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EDUC_LEVEL  HOUSEHOLD_HEAD_SEX  CURRENT_USE_TYPE  PATTERN_USE  CONTRACEPTIVE_USE_AND_INTENTION  WANT_LAST_CHILD  WANT_LAST_PREGNANCY  TOLD_ABT_SIDE_EFFECTS  SMOKE_CIGAR  RESIDING_WITH_PARTNER\n",
       "0         2.0                   1                 0          4.0                                4              1.0                    1                    NaN            0                    1.0\n",
       "1         2.0                   1                 0          4.0                                4              1.0                    1                    NaN            0                    1.0\n",
       "2         1.0                   1                 3          1.0                                1              1.0                    1                    1.0            0                    1.0\n",
       "3         2.0                   1                 0          4.0                                4              1.0                    1                    NaN            0                    1.0\n",
       "4         1.0                   1                 0          4.0                                4              1.0                    1                    NaN            1                    1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 6: Standardize mixed code/label columns\n",
    "\n",
    "# Example mapping dictionaries â€“ **adjust to your exact coding scheme**\n",
    "\n",
    "educ_level_map = {\n",
    "    \"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\": 4, \"5\": 5,\n",
    "    \"Primary\": 1, \"Elementary\": 1,\n",
    "    \"Secondary\": 3,\n",
    "    \"College\": 5, \"University\": 5\n",
    "}\n",
    "\n",
    "household_head_sex_map = {\n",
    "    \"1\": 1, \"2\": 2,\n",
    "    \"Male\": 1, \"Female\": 2\n",
    "}\n",
    "\n",
    "current_use_type_map = {\n",
    "    \"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3,\n",
    "    \"Non-user\": 0,\n",
    "    \"Current user\": 3\n",
    "}\n",
    "\n",
    "pattern_use_map = {\n",
    "    \"1\": 1, \"2\": 2, \"3\": 3, \"4\": 4,\n",
    "    \"Consistent\": 1, \"Irregular\": 2  # example, adjust\n",
    "}\n",
    "\n",
    "contraceptive_use_intention_map = {\n",
    "    \"1\": 1, \"2\": 2, \"3\": 3, \"4\": 4,\n",
    "    \"Using and intends to continue\": 1,\n",
    "    \"Using but intends to stop\": 2,\n",
    "    \"Not using but intends to use\": 3,\n",
    "    \"Not using and no intention\": 4\n",
    "}\n",
    "\n",
    "want_last_child_map = {\n",
    "    \"1\": 1, \"2\": 2, \"3\": 3,\n",
    "    \"Wanted then\": 1,\n",
    "    \"Wanted later\": 2,\n",
    "    \"Unwanted\": 3\n",
    "}\n",
    "\n",
    "want_last_pregnancy_map = {\n",
    "    \"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3,\n",
    "    \"No\": 0,\n",
    "    \"Yes\": 1\n",
    "}\n",
    "\n",
    "told_side_effects_map = {\n",
    "    \"0\": 0, \"1\": 1,\n",
    "    \"None\": 0,\n",
    "    \"Told\": 1\n",
    "}\n",
    "\n",
    "smoke_cigar_map = {\n",
    "    \"0\": 0, \"1\": 1,\n",
    "    \"No\": 0,\n",
    "    \"Yes\": 1\n",
    "}\n",
    "\n",
    "residing_with_partner_map = {\n",
    "    \"0\": 0, \"1\": 1, \"2\": 2,\n",
    "    \"No\": 0,\n",
    "    \"Yes\": 1\n",
    "}\n",
    "\n",
    "# Apply mappings\n",
    "def map_column(col, mapping):\n",
    "    return col.replace(mapping)\n",
    "\n",
    "mixed_mappings = {\n",
    "    \"EDUC_LEVEL\": educ_level_map,\n",
    "    \"HOUSEHOLD_HEAD_SEX\": household_head_sex_map,\n",
    "    \"CURRENT_USE_TYPE\": current_use_type_map,\n",
    "    \"PATTERN_USE\": pattern_use_map,\n",
    "    \"CONTRACEPTIVE_USE_AND_INTENTION\": contraceptive_use_intention_map,\n",
    "    \"WANT_LAST_CHILD\": want_last_child_map,\n",
    "    \"WANT_LAST_PREGNANCY\": want_last_pregnancy_map,\n",
    "    \"TOLD_ABT_SIDE_EFFECTS\": told_side_effects_map,\n",
    "    \"SMOKE_CIGAR\": smoke_cigar_map,\n",
    "    \"RESIDING_WITH_PARTNER\": residing_with_partner_map,\n",
    "}\n",
    "\n",
    "df_std = df.copy()\n",
    "\n",
    "for col, mapping in mixed_mappings.items():\n",
    "    if col in df_std.columns:\n",
    "        df_std[col] = map_column(df_std[col].astype(str), mapping)\n",
    "        # after mapping, try to cast to numeric\n",
    "        df_std[col] = pd.to_numeric(df_std[col], errors=\"coerce\")\n",
    "\n",
    "display(df_std[mixed_mappings.keys()].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dff8e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after dropping rows with missing target: (6612, 31)\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Target selection for this notebook (you can change)\n",
    "TARGET = \"CONTRACEPTIVE_USE_AND_INTENTION\"  # or \"CONTRACEPTIVE_METHOD\", \"CURRENT_USE_TYPE\"\n",
    "\n",
    "# Drop rows with missing target (simplest choice)\n",
    "df_model = df_std.dropna(subset=[TARGET]).copy()\n",
    "print(\"Shape after dropping rows with missing target:\", df_model.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07f02365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features: ['AGE', 'AGE_GRP', 'REGION', 'RELIGION', 'ETHNICITY', 'EDUC', 'HOUSEHOLD_HEAD_SEX', 'PARITY', 'CONTRACEPTIVE_METHOD', 'CURRENT_USE_TYPE', 'PATTERN_USE', 'CONTRACEPTIVE_USE_AND_INTENTION', 'WANT_LAST_PREGNANCY', 'SMOKE_CIGAR', 'MARITAL_STATUS', 'DESIRE_FOR_MORE_CHILDREN', 'OCCUPATION']\n",
      "Categorical features: ['CASEID', 'LAST_SOURCE_TYPE', 'MONTH_USE_CURRENT_METHOD', 'LAST_METHOD_DISCONTINUED', 'REASON_DISCONTINUED', 'INTENTION_USE', 'TOLD_ABT_SIDE_EFFECTS', 'RESIDING_WITH_PARTNER', 'HSBND_DESIRE_FOR_MORE_CHILDREN', 'HUSBANDS_EDUC', 'HUSBAND_AGE', 'PARTNER_EDUC']\n"
     ]
    }
   ],
   "source": [
    "# Identify column types after standardization\n",
    "numeric_features = [\n",
    "    \"AGE\", \"AGE_GRP\", \"REGION\", \"RELIGION\", \"ETHNICITY\", \"EDUC\",\n",
    "    \"HOUSEHOLD_HEAD_SEX\", \"PARITY\", \"CONTRACEPTIVE_METHOD\",\n",
    "    \"CURRENT_USE_TYPE\", \"PATTERN_USE\", \"CONTRACEPTIVE_USE_AND_INTENTION\",\n",
    "    \"WANT_LAST_PREGNANCY\", \"SMOKE_CIGAR\", \"MARITAL_STATUS\",\n",
    "    \"DESIRE_FOR_MORE_CHILDREN\", \"OCCUPATION\"\n",
    "]\n",
    "\n",
    "# Keep only numeric columns that actually exist\n",
    "numeric_features = [c for c in numeric_features if c in df_model.columns]\n",
    "\n",
    "categorical_features = [\n",
    "    \"CASEID\", \"LAST_SOURCE_TYPE\", \"MONTH_USE_CURRENT_METHOD\",\n",
    "    \"LAST_METHOD_DISCONTINUED\", \"REASON_DISCONTINUED\",\n",
    "    \"INTENTION_USE\", \"TOLD_ABT_SIDE_EFFECTS\", \"RESIDING_WITH_PARTNER\",\n",
    "    \"HSBND_DESIRE_FOR_MORE_CHILDREN\", \"HUSBANDS_EDUC\", \"HUSBAND_AGE\",\n",
    "    \"PARTNER_EDUC\"\n",
    "]\n",
    "\n",
    "categorical_features = [c for c in categorical_features if c in df_model.columns]\n",
    "\n",
    "print(\"Numeric features:\", numeric_features)\n",
    "print(\"Categorical features:\", categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "743d7f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CASEID                      0\n",
       "AGE_GRP                     0\n",
       "LAST_SOURCE_TYPE            0\n",
       "INTENTION_USE               0\n",
       "TOLD_ABT_SIDE_EFFECTS       0\n",
       "LAST_METHOD_DISCONTINUED    0\n",
       "CONTRACEPTIVE_METHOD        0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Helper: mode imputation for some key columns if you want to do it upfront\n",
    "def fill_mode(col):\n",
    "    mode_val = col.mode(dropna=True)\n",
    "    if len(mode_val) == 0:\n",
    "        return col\n",
    "    return col.fillna(mode_val.iloc[0])\n",
    "\n",
    "for col in [\"CASEID\", \"LAST_SOURCE_TYPE\", \"INTENTION_USE\", \"TOLD_ABT_SIDE_EFFECTS\",\n",
    "            \"LAST_METHOD_DISCONTINUED\", \"CONTRACEPTIVE_METHOD\", \"AGE_GRP\"]:\n",
    "    if col in df_model.columns:\n",
    "        df_model[col] = fill_mode(df_model[col])\n",
    "\n",
    "display(df_model[[\"CASEID\", \"AGE_GRP\", \"LAST_SOURCE_TYPE\", \"INTENTION_USE\",\n",
    "                  \"TOLD_ABT_SIDE_EFFECTS\", \"LAST_METHOD_DISCONTINUED\",\n",
    "                  \"CONTRACEPTIVE_METHOD\"]].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1eb7b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CASEID</th>\n",
       "      <th>MONTH_USE_CURRENT_METHOD</th>\n",
       "      <th>REASON_DISCONTINUED</th>\n",
       "      <th>HUSBAND_AGE</th>\n",
       "      <th>OCCUPATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Other</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Other</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Other</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td></td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Other</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Other</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CASEID MONTH_USE_CURRENT_METHOD REASON_DISCONTINUED HUSBAND_AGE OCCUPATION\n",
       "0  Other                                                       27          0\n",
       "1  Other                                                    Other         91\n",
       "2  Other                    Other                              25          0\n",
       "3  Other                                                       24          0\n",
       "4  Other                                                       32          0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 8: Rare category handling\n",
    "\n",
    "def group_rare_categories(series, min_freq=0.02):\n",
    "    freqs = series.value_counts(normalize=True)\n",
    "    rare_cats = freqs[freqs < min_freq].index\n",
    "    return series.where(~series.isin(rare_cats), other=\"Other\")\n",
    "\n",
    "high_cardinality_cols = [\n",
    "    \"CASEID\", \"MONTH_USE_CURRENT_METHOD\", \"REASON_DISCONTINUED\",\n",
    "    \"HUSBAND_AGE\", \"OCCUPATION\"\n",
    "]\n",
    "\n",
    "for col in high_cardinality_cols:\n",
    "    if col in df_model.columns:\n",
    "        df_model[col] = group_rare_categories(df_model[col].astype(str), min_freq=0.02)\n",
    "\n",
    "display(df_model[high_cardinality_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4262ac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Drop highly correlated features where necessary\n",
    "\n",
    "# Example: drop AGE_GRP if both AGE and AGE_GRP present\n",
    "if \"AGE\" in df_model.columns and \"AGE_GRP\" in df_model.columns:\n",
    "    df_model = df_model.drop(columns=[\"AGE_GRP\"])\n",
    "    if \"AGE_GRP\" in numeric_features:\n",
    "        numeric_features.remove(\"AGE_GRP\")\n",
    "\n",
    "# If target is CONTRACEPTIVE_USE_AND_INTENTION, remove highly correlated CURRENT_USE_TYPE\n",
    "if TARGET == \"CONTRACEPTIVE_USE_AND_INTENTION\" and \"CURRENT_USE_TYPE\" in df_model.columns:\n",
    "    df_model = df_model.drop(columns=[\"CURRENT_USE_TYPE\"])\n",
    "    if \"CURRENT_USE_TYPE\" in numeric_features:\n",
    "        numeric_features.remove(\"CURRENT_USE_TYPE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82d760bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final numeric features: ['AGE', 'REGION', 'RELIGION', 'ETHNICITY', 'EDUC', 'HOUSEHOLD_HEAD_SEX', 'PARITY', 'CONTRACEPTIVE_METHOD', 'PATTERN_USE', 'WANT_LAST_PREGNANCY', 'SMOKE_CIGAR', 'MARITAL_STATUS', 'DESIRE_FOR_MORE_CHILDREN', 'OCCUPATION']\n",
      "Final categorical features: ['CASEID', 'LAST_SOURCE_TYPE', 'MONTH_USE_CURRENT_METHOD', 'LAST_METHOD_DISCONTINUED', 'REASON_DISCONTINUED', 'INTENTION_USE', 'TOLD_ABT_SIDE_EFFECTS', 'RESIDING_WITH_PARTNER', 'HSBND_DESIRE_FOR_MORE_CHILDREN', 'HUSBANDS_EDUC', 'HUSBAND_AGE', 'PARTNER_EDUC']\n"
     ]
    }
   ],
   "source": [
    "# Reconfirm features after drops\n",
    "numeric_features = [c for c in numeric_features if c in df_model.columns and c != TARGET]\n",
    "categorical_features = [c for c in categorical_features if c in df_model.columns and c != TARGET]\n",
    "\n",
    "print(\"Final numeric features:\", numeric_features)\n",
    "print(\"Final categorical features:\", categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cde7e84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing transformers\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "    # no scaler needed for tree-based models\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5834b869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (5289, 28)\n",
      "Test shape: (1323, 28)\n",
      "Train target distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CONTRACEPTIVE_USE_AND_INTENTION\n",
       "1    45.698620\n",
       "4    24.522594\n",
       "2    15.106825\n",
       "3    14.671961\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 10: Train-test split with stratification\n",
    "\n",
    "X = df_model.drop(columns=[TARGET])\n",
    "y = df_model[TARGET]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "print(\"Train target distribution:\")\n",
    "display(y_train.value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca5ba096",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot use median strategy with non-numeric data:\ncould not convert string to float: 'NCR'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m      3\u001b[39m xgb_clf = XGBClassifier(\n\u001b[32m      4\u001b[39m     n_estimators=\u001b[32m300\u001b[39m,\n\u001b[32m      5\u001b[39m     max_depth=\u001b[32m5\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     random_state=\u001b[32m42\u001b[39m\n\u001b[32m     13\u001b[39m )\n\u001b[32m     15\u001b[39m xgb_pipeline = Pipeline(steps=[\n\u001b[32m     16\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mpreprocess\u001b[39m\u001b[33m\"\u001b[39m, preprocessor),\n\u001b[32m     17\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, xgb_clf)\n\u001b[32m     18\u001b[39m ])\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43mxgb_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m y_pred_xgb = xgb_pipeline.predict(X_test)\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== XGBoost performance ===\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\pipeline.py:613\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    606\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    607\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe `transform_input` parameter can only be set if metadata \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    608\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrouting is enabled. You can enable metadata routing using \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    609\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`sklearn.set_config(enable_metadata_routing=True)`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    610\u001b[39m     )\n\u001b[32m    612\u001b[39m routed_params = \u001b[38;5;28mself\u001b[39m._check_method_params(method=\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, props=params)\n\u001b[32m--> \u001b[39m\u001b[32m613\u001b[39m Xt = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    614\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[33m\"\u001b[39m\u001b[33mPipeline\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.steps) - \u001b[32m1\u001b[39m)):\n\u001b[32m    615\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\pipeline.py:547\u001b[39m, in \u001b[36mPipeline._fit\u001b[39m\u001b[34m(self, X, y, routed_params, raw_params)\u001b[39m\n\u001b[32m    540\u001b[39m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[32m    541\u001b[39m step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    542\u001b[39m     step_idx=step_idx,\n\u001b[32m    543\u001b[39m     step_params=routed_params[name],\n\u001b[32m    544\u001b[39m     all_params=raw_params,\n\u001b[32m    545\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m547\u001b[39m X, fitted_transformer = \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    548\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPipeline\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[32m    557\u001b[39m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[32m    558\u001b[39m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.steps[step_idx] = (name, fitted_transformer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\joblib\\memory.py:326\u001b[39m, in \u001b[36mNotMemorizedFunc.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\pipeline.py:1484\u001b[39m, in \u001b[36m_fit_transform_one\u001b[39m\u001b[34m(transformer, X, y, weight, message_clsname, message, params)\u001b[39m\n\u001b[32m   1482\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m   1483\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1484\u001b[39m         res = \u001b[43mtransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit_transform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1485\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1486\u001b[39m         res = transformer.fit(X, y, **params.get(\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, {})).transform(\n\u001b[32m   1487\u001b[39m             X, **params.get(\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m   1488\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\compose\\_column_transformer.py:999\u001b[39m, in \u001b[36mColumnTransformer.fit_transform\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    996\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    997\u001b[39m     routed_params = \u001b[38;5;28mself\u001b[39m._get_empty_routing()\n\u001b[32m--> \u001b[39m\u001b[32m999\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_func_on_transformers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_fit_transform_one\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumn_as_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result:\n\u001b[32m   1008\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_fitted_transformers([])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\compose\\_column_transformer.py:901\u001b[39m, in \u001b[36mColumnTransformer._call_func_on_transformers\u001b[39m\u001b[34m(self, X, y, func, column_as_labels, routed_params)\u001b[39m\n\u001b[32m    889\u001b[39m             extra_args = {}\n\u001b[32m    890\u001b[39m         jobs.append(\n\u001b[32m    891\u001b[39m             delayed(func)(\n\u001b[32m    892\u001b[39m                 transformer=clone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[32m   (...)\u001b[39m\u001b[32m    898\u001b[39m             )\n\u001b[32m    899\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m901\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    903\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    904\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mExpected 2D array, got 1D array instead\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\utils\\parallel.py:91\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     79\u001b[39m warning_filters = (\n\u001b[32m     80\u001b[39m     filters_func() \u001b[38;5;28;01mif\u001b[39;00m filters_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m warnings.filters\n\u001b[32m     81\u001b[39m )\n\u001b[32m     83\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     84\u001b[39m     (\n\u001b[32m     85\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     90\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\utils\\parallel.py:184\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    180\u001b[39m                 this_warning_filter_dict[special_key] = this_value.pattern\n\u001b[32m    182\u001b[39m         warnings.filterwarnings(**this_warning_filter_dict, append=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\pipeline.py:1484\u001b[39m, in \u001b[36m_fit_transform_one\u001b[39m\u001b[34m(transformer, X, y, weight, message_clsname, message, params)\u001b[39m\n\u001b[32m   1482\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m   1483\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1484\u001b[39m         res = \u001b[43mtransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit_transform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1485\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1486\u001b[39m         res = transformer.fit(X, y, **params.get(\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, {})).transform(\n\u001b[32m   1487\u001b[39m             X, **params.get(\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m   1488\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\pipeline.py:689\u001b[39m, in \u001b[36mPipeline.fit_transform\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    683\u001b[39m last_step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    684\u001b[39m     step_idx=\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) - \u001b[32m1\u001b[39m,\n\u001b[32m    685\u001b[39m     step_params=routed_params[\u001b[38;5;28mself\u001b[39m.steps[-\u001b[32m1\u001b[39m][\u001b[32m0\u001b[39m]],\n\u001b[32m    686\u001b[39m     all_params=params,\n\u001b[32m    687\u001b[39m )\n\u001b[32m    688\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(last_step, \u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m689\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlast_step\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m        \u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit_transform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    693\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m last_step.fit(Xt, y, **last_step_params[\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m]).transform(\n\u001b[32m    694\u001b[39m         Xt, **last_step_params[\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    695\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\base.py:910\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    907\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, **fit_params).transform(X)\n\u001b[32m    908\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    909\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m910\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m.transform(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\impute\\_base.py:447\u001b[39m, in \u001b[36mSimpleImputer.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    431\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Fit the imputer on `X`.\u001b[39;00m\n\u001b[32m    432\u001b[39m \n\u001b[32m    433\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    445\u001b[39m \u001b[33;03m        Fitted estimator.\u001b[39;00m\n\u001b[32m    446\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m     X = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_fit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    449\u001b[39m     \u001b[38;5;66;03m# default fill_value is 0 for numerical input and \"missing_value\"\u001b[39;00m\n\u001b[32m    450\u001b[39m     \u001b[38;5;66;03m# otherwise\u001b[39;00m\n\u001b[32m    451\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\impute\\_base.py:372\u001b[39m, in \u001b[36mSimpleImputer._validate_input\u001b[39m\u001b[34m(self, X, in_fit)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcould not convert\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(ve):\n\u001b[32m    367\u001b[39m     new_ve = \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    368\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot use \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m strategy with non-numeric data:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    369\u001b[39m             \u001b[38;5;28mself\u001b[39m.strategy, ve\n\u001b[32m    370\u001b[39m         )\n\u001b[32m    371\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m new_ve \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    374\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ve\n",
      "\u001b[31mValueError\u001b[39m: Cannot use median strategy with non-numeric data:\ncould not convert string to float: 'NCR'"
     ]
    }
   ],
   "source": [
    "# Step 11a: XGBoost pipeline\n",
    "\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective=\"multi:softprob\",  # or 'binary:logistic' for binary targets\n",
    "    tree_method=\"hist\",\n",
    "    eval_metric=\"mlogloss\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_pipeline = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"model\", xgb_clf)\n",
    "])\n",
    "\n",
    "xgb_pipeline.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_pipeline.predict(X_test)\n",
    "\n",
    "print(\"=== XGBoost performance ===\")\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288aad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11b: Decision Tree pipeline\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(\n",
    "    max_depth=5,\n",
    "    min_samples_leaf=50,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\"  # helpful for imbalance\n",
    ")\n",
    "\n",
    "dt_pipeline = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"model\", dt_clf)\n",
    "])\n",
    "\n",
    "dt_pipeline.fit(X_train, y_train)\n",
    "y_pred_dt = dt_pipeline.predict(X_test)\n",
    "\n",
    "print(\"=== Decision Tree performance ===\")\n",
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12b83b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Step 11c: Simple hybrid combiner\n",
    "\n",
    "# Make sure we can handle non-numeric labels consistently\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)\n",
    "\n",
    "# Refit XGBoost with encoded labels, if needed\n",
    "xgb_clf_hybrid = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective=\"multi:softprob\",\n",
    "    tree_method=\"hist\",\n",
    "    eval_metric=\"mlogloss\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_pipeline_hybrid = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"model\", xgb_clf_hybrid)\n",
    "])\n",
    "\n",
    "xgb_pipeline_hybrid.fit(X_train, y_train_enc)\n",
    "\n",
    "dt_clf_hybrid = DecisionTreeClassifier(\n",
    "    max_depth=5,\n",
    "    min_samples_leaf=50,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "dt_pipeline_hybrid = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"model\", dt_clf_hybrid)\n",
    "])\n",
    "\n",
    "dt_pipeline_hybrid.fit(X_train, y_train_enc)\n",
    "\n",
    "# Get probabilities from XGBoost\n",
    "proba_xgb = xgb_pipeline_hybrid.predict_proba(X_test)\n",
    "pred_xgb_enc = proba_xgb.argmax(axis=1)\n",
    "conf_xgb = proba_xgb.max(axis=1)\n",
    "\n",
    "# Tree predictions\n",
    "pred_dt_enc = dt_pipeline_hybrid.predict(X_test)\n",
    "\n",
    "# Hybrid: if XGBoost confidence < threshold, use Decision Tree\n",
    "CONF_THRESHOLD = 0.6\n",
    "hybrid_pred_enc = np.where(conf_xgb < CONF_THRESHOLD, pred_dt_enc, pred_xgb_enc)\n",
    "\n",
    "# Decode back to original labels\n",
    "hybrid_pred = le.inverse_transform(hybrid_pred_enc)\n",
    "\n",
    "print(\"=== Hybrid (XGBoost + Decision Tree) performance ===\")\n",
    "print(classification_report(y_test, hybrid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0e72f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
